{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b90e025b",
   "metadata": {},
   "source": [
    "# Identification of Different Medicinal Plants/Raw materials through Image Processing Using Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd840f18",
   "metadata": {},
   "source": [
    "In a project aiming to identify medicinal plants and raw materials through image processing with machine learning, the data preparation approach has been enhanced. Convolutional Neural Networks (CNNs) are incorporated to improve image analysis.\n",
    "\n",
    "This code gathers images from a source folder and stores them in a separate destination folder. What sets this approach apart is the utilization of CNNs, enabling the project to discern intricate image details. This analysis enhances plant identification precision through machine learning techniques.\n",
    "\n",
    "By employing CNNs, the dataset becomes better suited for training and feature extraction, ultimately improving the accuracy of the plant identification process. This step signifies a critical advancement in the project's capabilities, enabling more reliable and detailed results when identifying different medicinal plants and raw materials."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f19da3f",
   "metadata": {},
   "source": [
    "## Importing Necessary Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31dec30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot  as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34dc3da9",
   "metadata": {},
   "source": [
    "## Splitting the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd655c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Combined\"\n",
    "train_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Train\"\n",
    "validation_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Val\"\n",
    "test_dataset = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Test\"\n",
    "# train_ratio = 0.8\n",
    "\n",
    "# os.makedirs(train_dataset, exist_ok=True)\n",
    "# os.makedirs(validation_dataset, exist_ok=True)\n",
    "# os.makedirs(test_dataset, exist_ok=True)\n",
    "\n",
    "# for class_name in os.listdir(src_dataset):\n",
    "#     class_src = os.path.join(src_dataset, class_name)\n",
    "#     class_train = os.path.join(train_dataset, class_name)\n",
    "#     class_validation = os.path.join(validation_dataset, class_name)\n",
    "#     class_test = os.path.join(test_dataset, class_name)\n",
    "\n",
    "#     os.makedirs(class_train, exist_ok=True)\n",
    "#     os.makedirs(class_validation, exist_ok=True)\n",
    "#     os.makedirs(class_test, exist_ok=True)\n",
    "\n",
    "#     files = os.listdir(class_src)\n",
    "#     random.shuffle(files)\n",
    "\n",
    "#     split_index_train = int(train_ratio * len(files))\n",
    "#     split_index_validation = int((train_ratio + 0.1) * len(files))\n",
    "\n",
    "#     train_files = files[:split_index_train]\n",
    "#     validation_files = files[split_index_train:split_index_validation]\n",
    "#     test_files = files[split_index_validation:]\n",
    "\n",
    "#     for file in train_files:\n",
    "#         shutil.copy(os.path.join(class_src, file), os.path.join(class_train, file))\n",
    "\n",
    "#     for file in validation_files:\n",
    "#         shutil.copy(os.path.join(class_src, file), os.path.join(class_validation, file))\n",
    "\n",
    "#     for file in test_files:\n",
    "#         shutil.copy(os.path.join(class_src, file), os.path.join(class_test, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b05b86",
   "metadata": {},
   "source": [
    "## Batch Image Resizing "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814284e",
   "metadata": {},
   "source": [
    "### 1. For Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f371472",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "main_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Train\"\n",
    "output_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\TrainResize\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# target_size = (256, 256)\n",
    "\n",
    "# for root, _, files in os.walk(main_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             img = Image.open(image_path)\n",
    "#             resized_img = img.resize(target_size)\n",
    "\n",
    "#             # Get the relative path within the main folder\n",
    "#             relative_path = os.path.relpath(root, main_folder)\n",
    "\n",
    "#             # Create the new folder in the output folder\n",
    "#             new_folder_path = os.path.join(output_folder, relative_path)\n",
    "#             os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "#             # Output path for the resized image\n",
    "#             output_path = os.path.join(new_folder_path, file)\n",
    "\n",
    "#             resized_img.save(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b51fe0",
   "metadata": {},
   "source": [
    "### 2. For Validation Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05cd7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Val\"\n",
    "output_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\ValResize\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# target_size = (256, 256)\n",
    "\n",
    "# for root, _, files in os.walk(main_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             img = Image.open(image_path)\n",
    "#             resized_img = img.resize(target_size)\n",
    "\n",
    "#             # Get the relative path within the main folder\n",
    "#             relative_path = os.path.relpath(root, main_folder)\n",
    "\n",
    "#             # Create the new folder in the output folder\n",
    "#             new_folder_path = os.path.join(output_folder, relative_path)\n",
    "#             os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "#             # Output path for the resized image\n",
    "#             output_path = os.path.join(new_folder_path, file)\n",
    "\n",
    "#             resized_img.save(output_path)       "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06ecac8",
   "metadata": {},
   "source": [
    "### 3. For Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb128a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_folder =  r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\Test\"\n",
    "output_folder = r\"C:\\Users\\Admin\\Downloads\\Augmented Data-20231216T051848Z-001\\Augmented Data\\TestResize\"\n",
    "# os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# target_size = (256, 256)\n",
    "\n",
    "# for root, _, files in os.walk(main_folder):\n",
    "#     for file in files:\n",
    "#         if file.lower().endswith(('.jpg', '.jpeg', '.png', '.gif')):\n",
    "#             image_path = os.path.join(root, file)\n",
    "#             img = Image.open(image_path)\n",
    "#             resized_img = img.resize(target_size)\n",
    "\n",
    "#             # Get the relative path within the main folder\n",
    "#             relative_path = os.path.relpath(root, main_folder)\n",
    "\n",
    "#             # Create the new folder in the output folder\n",
    "#             new_folder_path = os.path.join(output_folder, relative_path)\n",
    "#             os.makedirs(new_folder_path, exist_ok=True)\n",
    "\n",
    "#             # Output path for the resized image\n",
    "#             output_path = os.path.join(new_folder_path, file)\n",
    "\n",
    "#             resized_img.save(output_path)     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f336b4e",
   "metadata": {},
   "source": [
    "## Rescaling and Data Augmentation for Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aceba7a",
   "metadata": {},
   "source": [
    "In an image classification project, data is optimized for machine learning by rescaling images for consistency and applying data augmentation for improved model robustness. These techniques enhance the dataset for accurate identification of medicinal plants and raw materials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0908259f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12276 images belonging to 26 classes.\n",
      "Found 1534 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "batch_size = 11\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    directory=train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical' \n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    directory=validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'  \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a85dff",
   "metadata": {},
   "source": [
    "## Creating a Convolutional Neural Network (CNN) Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e71608c",
   "metadata": {},
   "source": [
    "This code segment outlines the creation of a Convolutional Neural Network (CNN) model. CNNs are essential for image-related tasks, and this model is being designed for image classification in our project. The model architecture includes convolutional and pooling layers, followed by fully connected layers, culminating in an output layer for classification. This foundational step lays the groundwork for effective image recognition in our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b669847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', \n",
    "                           input_shape=(256, 256, 3), padding='same'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'), \n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Flatten(),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.5), \n",
    "    tf.keras.layers.Dense(26, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2015280",
   "metadata": {},
   "source": [
    "## Customizing Learning Rate for Adam Optimizer in a Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeb80bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b1d56df",
   "metadata": {},
   "source": [
    "## Training a Keras Model on Image Data Using Data Generators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e93c4b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1116/1116 [==============================] - 1142s 1s/step - loss: 2.8901 - accuracy: 0.1553 - val_loss: 2.7167 - val_accuracy: 0.1682\n",
      "Epoch 2/50\n",
      "1116/1116 [==============================] - 1184s 1s/step - loss: 2.4691 - accuracy: 0.2480 - val_loss: 1.9640 - val_accuracy: 0.3677\n",
      "Epoch 3/50\n",
      "1116/1116 [==============================] - 1150s 1s/step - loss: 2.0219 - accuracy: 0.3694 - val_loss: 1.4589 - val_accuracy: 0.5482\n",
      "Epoch 4/50\n",
      "1116/1116 [==============================] - 1139s 1s/step - loss: 1.6516 - accuracy: 0.4782 - val_loss: 1.3182 - val_accuracy: 0.5535\n",
      "Epoch 5/50\n",
      "1116/1116 [==============================] - 1138s 1s/step - loss: 1.4461 - accuracy: 0.5362 - val_loss: 1.0330 - val_accuracy: 0.6630\n",
      "Epoch 6/50\n",
      "1116/1116 [==============================] - 1177s 1s/step - loss: 1.3571 - accuracy: 0.5664 - val_loss: 1.0964 - val_accuracy: 0.6382\n",
      "Epoch 7/50\n",
      "1116/1116 [==============================] - 1185s 1s/step - loss: 1.2378 - accuracy: 0.6039 - val_loss: 0.8947 - val_accuracy: 0.7021\n",
      "Epoch 8/50\n",
      "1116/1116 [==============================] - 1186s 1s/step - loss: 1.1647 - accuracy: 0.6275 - val_loss: 0.9814 - val_accuracy: 0.6767\n",
      "Epoch 9/50\n",
      "1116/1116 [==============================] - 1183s 1s/step - loss: 1.0952 - accuracy: 0.6453 - val_loss: 0.8104 - val_accuracy: 0.7360\n",
      "Epoch 10/50\n",
      "1116/1116 [==============================] - 1183s 1s/step - loss: 1.0297 - accuracy: 0.6644 - val_loss: 0.7253 - val_accuracy: 0.7601\n",
      "Epoch 11/50\n",
      "1116/1116 [==============================] - 1184s 1s/step - loss: 0.9763 - accuracy: 0.6834 - val_loss: 0.7194 - val_accuracy: 0.7797\n",
      "Epoch 12/50\n",
      "1116/1116 [==============================] - 1237s 1s/step - loss: 0.8807 - accuracy: 0.7177 - val_loss: 0.9670 - val_accuracy: 0.7040\n",
      "Epoch 14/50\n",
      "1116/1116 [==============================] - 1233s 1s/step - loss: 0.8331 - accuracy: 0.7292 - val_loss: 0.5755 - val_accuracy: 0.8077\n",
      "Epoch 15/50\n",
      " 786/1116 [====================>.........] - ETA: 5:52 - loss: 0.8031 - accuracy: 0.7436"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 1238s 1s/step - loss: 0.5754 - accuracy: 0.8150 - val_loss: 0.4765 - val_accuracy: 0.8533\n",
      "Epoch 25/50\n",
      "1116/1116 [==============================] - 1237s 1s/step - loss: 0.5679 - accuracy: 0.8216 - val_loss: 0.3455 - val_accuracy: 0.8950\n",
      "Epoch 26/50\n",
      "1116/1116 [==============================] - 1238s 1s/step - loss: 0.5264 - accuracy: 0.8369 - val_loss: 0.3269 - val_accuracy: 0.8970\n",
      "Epoch 27/50\n",
      " 427/1116 [==========>...................] - ETA: 12:13 - loss: 0.4571 - accuracy: 0.8533"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 1234s 1s/step - loss: 0.4192 - accuracy: 0.8694 - val_loss: 0.5662 - val_accuracy: 0.8559\n",
      "Epoch 35/50\n",
      "1116/1116 [==============================] - 1235s 1s/step - loss: 0.4568 - accuracy: 0.8583 - val_loss: 0.2213 - val_accuracy: 0.9309\n",
      "Epoch 36/50\n",
      "  90/1116 [=>............................] - ETA: 18:11 - loss: 0.4223 - accuracy: 0.8747"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 1236s 1s/step - loss: 0.4186 - accuracy: 0.8739 - val_loss: 0.4785 - val_accuracy: 0.8644\n",
      "Epoch 38/50\n",
      " 949/1116 [========================>.....] - ETA: 2:58 - loss: 0.4113 - accuracy: 0.8760"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 1236s 1s/step - loss: 0.3869 - accuracy: 0.8822 - val_loss: 0.2476 - val_accuracy: 0.9407\n",
      "Epoch 48/50\n",
      " 363/1116 [========>.....................] - ETA: 13:22 - loss: 0.3640 - accuracy: 0.8835"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1116/1116 [==============================] - 1238s 1s/step - loss: 0.3597 - accuracy: 0.8934 - val_loss: 0.2473 - val_accuracy: 0.9237\n",
      "Epoch 50/50\n",
      " 934/1116 [========================>.....] - ETA: 3:13 - loss: 0.3585 - accuracy: 0.8924"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=len(train_generator),\n",
    "    epochs=50,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(validation_generator)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0c66681",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "# plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Accuracy')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d070aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(history.history['loss'])\n",
    "# plt.plot(history.history['val_loss'])\n",
    "# plt.title('model loss')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.legend(['train', 'val'], loc='upper left')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2081172a",
   "metadata": {},
   "source": [
    "## Evaluating a Keras Model on a Test Dataset Using a Data Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7f651070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1547 images belonging to 26 classes.\n",
      "141/141 [==============================] - 43s 301ms/step - loss: 0.1606 - accuracy: 0.9554\n",
      "Test Accuracy: 95.54%\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    directory=test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical' \n",
    ")\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_generator, steps=len(test_generator))\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b3b0948e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m model_version \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m([\u001b[38;5;28mint\u001b[39m(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Admin/Desktop/model\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m+\u001b[39m [\u001b[38;5;241m0\u001b[39m]]) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Save the 'history' model with the calculated version number\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m history\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/Admin/Desktop/model/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_version\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assuming 'history' is your Keras model\n",
    "# model_version calculation remains the same\n",
    "model_version = max([int(i) for i in os.listdir(\"C:/Users/Admin/Desktop/model\") + [0]]) + 1\n",
    "\n",
    "# Save the 'history' model with the calculated version number\n",
    "history.save(f\"C:/Users/Admin/Desktop/model/{model_version}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d71dff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"../leaves.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
